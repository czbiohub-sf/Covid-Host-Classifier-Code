{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_norm_first_gene_counts_df = pd.read_csv(\"original_and_validation_below_ct_30_vst.csv\",low_memory=False).T\n",
    "first_headers = pre_norm_first_gene_counts_df.iloc[0]\n",
    "pre_norm_first_gene_counts_df = pre_norm_first_gene_counts_df[1:]\n",
    "pre_norm_first_gene_counts_df.columns = first_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_IDs = pd.read_csv(\"original_and_validation_below_ct_30_vst.csv\",low_memory=False).columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSG_trans = pd.read_csv('gene2name.txt',low_memory=False, index_col = 0, header = None, sep = '\\t').T\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gene2name.txt', 'r') as f:\n",
    "    E2N = {}\n",
    "    for line in f:\n",
    "        ecode, name, _ = line.split()\n",
    "        E2N[ecode] = name\n",
    "\n",
    "N2E = {v: k for k,v in E2N.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I2E = dict(first_headers)\n",
    "E2I = {v: k for k,v in I2E.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I2N = {v: E2N[k] for v, k in I2E.items()}\n",
    "N2I = {v: k for k,v in I2N.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_std = True)\n",
    "scaler.fit(pre_norm_first_gene_counts_df)\n",
    "first_gene_counts_df = scaler.transform(pre_norm_first_gene_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCSF_meta = pd.read_csv('UCSF_samples_metadata.csv', index_col = 'czb_id').loc[sample_IDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_second_SC2_3way = UCSF_meta['viral_status']\n",
    "first_second_SC2_3way = np.char.capitalize(first_second_SC2_3way.values.astype('str'))\n",
    "first_second_SC2_3way[first_second_SC2_3way == 'Other_virus'] = 'Other virus'\n",
    "first_second_SC2_3way[first_second_SC2_3way == 'No_virus'] = 'No virus'\n",
    "\n",
    "first_second_SC2 = first_second_SC2_3way == 'Sc2'\n",
    "\n",
    "rpm = UCSF_meta['sc2_rpm'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpm_first_gene_counts_df = np.concatenate((first_gene_counts_df, rpm.reshape((-1, 1))), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Training and Testing Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 8675309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits the data into training and validation datasets (70:30)\n",
    "\n",
    "[train_ind, test_ind] = train_test_split(np.arange(318), random_state = seed, test_size = 0.3\n",
    "                                         , stratify = 2*first_second_SC2\n",
    "                                        )\n",
    "\n",
    "TRcomb_counts = first_gene_counts_df[train_ind]\n",
    "TEcomb_counts = first_gene_counts_df[test_ind]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TRcomb_SC2 = first_second_SC2[train_ind]\n",
    "TEcomb_SC2 = first_second_SC2[test_ind]\n",
    "\n",
    "\n",
    "rpm_TRcomb_counts = rpm_first_gene_counts_df[train_ind]\n",
    "rpm_TEcomb_counts = rpm_first_gene_counts_df[test_ind]\n",
    "\n",
    "\n",
    "\n",
    "#Uncommment to use data without centering and scaling\n",
    "\n",
    "\n",
    "#TRcomb_counts = pre_norm_first_gene_counts_df.values[train_ind]\n",
    "#TEcomb_counts = pre_norm_first_gene_counts_df.values[test_ind]\n",
    "\n",
    "#rpm_TRcomb_counts = rpm_first_gene_counts_df[train_ind]\n",
    "#rpm_TEcomb_counts = rpm_first_gene_counts_df[test_ind]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 2-gene sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given the current gene set, finds the top 3 genes by how much they increase performance when added to the model.\n",
    "\n",
    "def next_three(genes):\n",
    "    \n",
    "    \n",
    "    first_all_scores = []\n",
    "\n",
    "    for i in range(TRcomb_counts.shape[1]):\n",
    "        if not i%100: print(i)\n",
    "        clf = SVC(gamma = 'auto', probability = True)\n",
    "        score = cross_validate(clf, TRcomb_counts[:, genes + [i]], TRcomb_SC2, scoring='roc_auc', cv=StratifiedKFold(n_splits=5, shuffle=True))\n",
    "        av = np.average(score['test_score'])\n",
    "        first_all_scores.append(av)\n",
    "    \n",
    "    \n",
    "    x = -2000\n",
    "    barset = np.argsort(first_all_scores)[x:]\n",
    "    bar = first_all_scores[barset[0]]\n",
    "    \n",
    "    \n",
    "    second_all_scores = []\n",
    "\n",
    "    for i in barset:\n",
    "        cur_scores = []\n",
    "        print(i)\n",
    "        for j in range(10):\n",
    "            clf = SVC(gamma = 'auto', probability = True)\n",
    "            score = cross_validate(clf, TRcomb_counts[:, genes + [i]], TRcomb_SC2, scoring='roc_auc', cv=StratifiedKFold(n_splits=5, shuffle=True))\n",
    "            av = np.average(score['test_score'])\n",
    "            if av < bar:\n",
    "                cur_scores = np.zeros(10)\n",
    "                break\n",
    "            cur_scores.append(av)\n",
    "            \n",
    "        second_all_scores.append(cur_scores)\n",
    "    \n",
    "    \n",
    "    onlyset = np.where(np.average(second_all_scores, axis = 1) != 0)[0]\n",
    "    \n",
    "    \n",
    "    third_all_scores = []\n",
    "    for i in barset[onlyset]:\n",
    "        cur_scores = []\n",
    "        print(i)\n",
    "        for j in range(100):\n",
    "            clf = SVC(gamma = 'auto', probability = True)\n",
    "            score = cross_validate(clf, TRcomb_counts[:, genes + [i]], TRcomb_SC2, scoring='roc_auc', cv=StratifiedKFold(n_splits=5, shuffle=True))\n",
    "            av = np.average(score['test_score'])\n",
    "            cur_scores.append(av)\n",
    "        third_all_scores.append(cur_scores)\n",
    "    \n",
    "    return barset[onlyset][np.argpartition(np.average(third_all_scores, axis = 1), -3)[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_three([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_three([6589])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_three([6487])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_three([5043])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate performance of resulting gene sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a gene set, generates the following five scores:\n",
    "#\n",
    "#   CV score on the training cohort\n",
    "#   CV score on the testing cohort\n",
    "#   Score on the testing cohort when trained on the training cohort\n",
    "#   CV score on the training cohort with rpm\n",
    "#   Score on the testing cohort when trained on the training cohort with rpm\n",
    "\n",
    "def five_scores(gene_set):\n",
    "    \n",
    "    print(ENSG_trans[first_headers[gene_set]].iloc[0].values)\n",
    "    \n",
    "    \n",
    "    cur_scores = []\n",
    "    for i in range(10000):\n",
    "        clf = SVC(gamma = 'auto', probability = True)\n",
    "        score = cross_validate(clf, TRcomb_counts[:, gene_set], TRcomb_SC2, scoring='roc_auc', cv=StratifiedKFold(n_splits=5, shuffle=True))\n",
    "        av = np.average(score['test_score'])\n",
    "        cur_scores.append(av)\n",
    "    \n",
    "    print(np.average(cur_scores), np.std(cur_scores))\n",
    "    \n",
    "    \n",
    "    \n",
    "    cur_scores = []\n",
    "    for i in range(10000):\n",
    "        clf = SVC(gamma = 'auto', probability = True)\n",
    "        score = cross_validate(clf, TEcomb_counts[:, gene_set], TEcomb_SC2, scoring='roc_auc', cv=StratifiedKFold(n_splits=5, shuffle=True))\n",
    "        av = np.average(score['test_score'])\n",
    "        cur_scores.append(av)\n",
    "    \n",
    "    print(np.average(cur_scores), np.std(cur_scores))\n",
    "    \n",
    "    \n",
    "    \n",
    "    X = TRcomb_counts[:, gene_set]\n",
    "    y = TRcomb_SC2\n",
    "    clf = SVC(gamma = 'auto', probability = True)\n",
    "    clf.fit(X, y)\n",
    "    print(roc_auc_score(TEcomb_SC2, clf.predict_proba(TEcomb_counts[:, gene_set])[:, 1]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    cur_scores = []\n",
    "    for i in range(10000):\n",
    "        clf = SVC(gamma = 'auto', probability = True)\n",
    "        score = cross_validate(clf, rpm_TRcomb_counts[:, gene_set + [-1]], TRcomb_SC2, scoring='roc_auc', cv=StratifiedKFold(n_splits=5, shuffle=True))\n",
    "        av = np.average(score['test_score'])\n",
    "        cur_scores.append(av)\n",
    "    \n",
    "    print(np.average(cur_scores), np.std(cur_scores))\n",
    "    \n",
    "    \n",
    "    \n",
    "    X = rpm_TRcomb_counts[:, gene_set + [-1]]\n",
    "    y = TRcomb_SC2\n",
    "    clf = SVC(gamma = 'auto', probability = True)\n",
    "    clf.fit(X, y)\n",
    "    print(roc_auc_score(TEcomb_SC2, clf.predict_proba(rpm_TEcomb_counts[:, gene_set + [-1]])[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "for gene_set in [[6589, 12501], [6589, 619], [6589, 8318],\n",
    "                [6487, 7921], [6487, 10579], [6487, 8318],\n",
    "                [5043, 8318], [5043, 10097], [5043, 11895]]:\n",
    "    \n",
    "    five_scores(gene_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = ['IFI6, GRINA', 'IFI44L, PTAFR', 'IFI6, C15orf48', 'IFI6, GBP5', 'IFI44L, GBP5']\n",
    "all_inds = [[5043, 11895], [6487, 10579], [5043, 10097], [5043, 8318], [6487, 8318]]\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for i in range(5):\n",
    "    text = all_text[i]\n",
    "    comb_inds = all_inds[i]\n",
    "    clf = SVC(gamma = 'auto', probability = True)\n",
    "    clf.fit(rpm_TRcomb_counts[:, comb_inds], TRcomb_SC2)\n",
    "    curve = plot_roc_curve(clf, rpm_TEcomb_counts[:, comb_inds], TEcomb_SC2, ax = ax)\n",
    "    #curve.line_.set_color('darkorange')\n",
    "    curve.line_.set_label(text+' (AUC = %.2f)' % curve.roc_auc)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='navy', alpha=0.8)\n",
    "ax.legend(loc = 4, bbox_to_anchor=(1.62, 0))\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.savefig('Figure 1b.pdf', bbox_inches = 'tight', dpi = 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Pairplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(first_gene_counts_df, columns = first_headers)\n",
    "data['Status'] = first_second_SC2_3way\n",
    "data['SC'] = np.array(['Sc2 Neg', 'Sc2 Pos'])[(first_second_SC2_3way == 'Sc2')+0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = ['IFI6', 'GBP5']\n",
    "\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "pal = dict(zip(data.Status.unique(),['#1180ff', 'gray', 'red']))\n",
    "\n",
    "g = sns.pairplot(data, vars = [N2E[n] for n in genes], hue = 'Status', palette = pal, plot_kws = dict(alpha = 0.5), diag_kws=dict(common_norm = False), aspect = 1.1)\n",
    "\n",
    "replacements = dict(zip([N2E[n] for n in genes], genes))\n",
    "\n",
    "for i in range(len(genes)):\n",
    "    for j in range(len(genes)):\n",
    "        xlabel = g.axes[i][j].get_xlabel()\n",
    "        ylabel = g.axes[i][j].get_ylabel()\n",
    "        if xlabel in replacements.keys():\n",
    "            g.axes[i][j].set_xlabel(replacements[xlabel], fontsize = 30)\n",
    "        if ylabel in replacements.keys():\n",
    "            g.axes[i][j].set_ylabel(replacements[ylabel], rotation = 0, horizontalalignment = 'right', verticalalignment = 'center', fontsize = 30)\n",
    "\n",
    "plt.setp(g._legend.get_texts(), fontsize='20', verticalalignment='center')\n",
    "plt.setp(g._legend.get_title(), fontsize='30')\n",
    "plt.setp(g._legend, bbox_to_anchor=(1.3, 0.5))\n",
    "\n",
    "for line in g._legend.legendHandles:\n",
    "    line.set_sizes([300, 300])\n",
    "\n",
    "tbbox = g.fig.get_tightbbox(g.fig.canvas.get_renderer())\n",
    "g.savefig('Figure 2a.pdf', bbox_inches = tbbox, dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = ['IFI6', 'GBP5']\n",
    "\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "pal = dict(zip(data.SC.unique(),['#1180ff', 'gray']))\n",
    "\n",
    "g = sns.pairplot(data, vars = [N2E[n] for n in genes], hue = 'SC', palette = pal, plot_kws = dict(alpha = 0.5), diag_kws=dict(common_norm = False), aspect = 1.1)\n",
    "\n",
    "replacements = dict(zip([N2E[n] for n in genes], genes))\n",
    "\n",
    "for i in range(len(genes)):\n",
    "    for j in range(len(genes)):\n",
    "        xlabel = g.axes[i][j].get_xlabel()\n",
    "        ylabel = g.axes[i][j].get_ylabel()\n",
    "        if xlabel in replacements.keys():\n",
    "            g.axes[i][j].set_xlabel(replacements[xlabel], fontsize = 30)\n",
    "        if ylabel in replacements.keys():\n",
    "            g.axes[i][j].set_ylabel(replacements[ylabel], rotation = 0, horizontalalignment = 'right', verticalalignment = 'center', fontsize = 30)\n",
    "\n",
    "plt.setp(g._legend.get_texts(), fontsize='20', verticalalignment='center')\n",
    "plt.setp(g._legend.get_title(), text=\"Status\", fontsize='30')\n",
    "plt.setp(g._legend, bbox_to_anchor=(1.3, 0.5))\n",
    "\n",
    "for line in g._legend.legendHandles:\n",
    "    line.set_sizes([300, 300])\n",
    "\n",
    "g.savefig('Figure 1b.pdf', bbox_inches = tbbox, dpi = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Cornell Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornell_counts = pd.read_csv('Cornell_counts/cornell_subset_vst.csv')\n",
    "cornell_counts.index = cornell_counts['Unnamed: 0']\n",
    "cornell_counts = cornell_counts.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornell_metatable = pd.read_csv('Cornell_counts/NewYork_samples_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corn_SC2 = []\n",
    "\n",
    "for sid in cornell_counts.columns:\n",
    "    corn_SC2.append(cornell_metatable.loc[cornell_metatable['SampleID'] == sid]['Class'].iloc[0] == 'Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corn_scaler = StandardScaler()\n",
    "corn_scaler.fit(cornell_counts.T)\n",
    "scaled_cornell_counts = corn_scaler.transform(cornell_counts.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loops over a number of gene sets to generate the following two scores:\n",
    "#\n",
    "#   CV score on the validation cohort\n",
    "#   Score on the validation cohort when trained on the training cohort\n",
    "\n",
    "all_pairs = [['HERC6', 'COA3'], \n",
    "             ['HERC6', 'TNIP3'], \n",
    "             ['HERC6', 'GBP5'], \n",
    "             ['IFI44L', 'FCGR1A'], \n",
    "             ['IFI44L', 'PTAFR'], \n",
    "             ['IFI44L', 'GBP5'], \n",
    "             ['IFI6', 'GBP5'], \n",
    "             ['IFI6', 'C15orf48'], \n",
    "             ['IFI6', 'GRINA']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display = []\n",
    "\n",
    "for gene_set in tqdm(all_pairs, leave=False):\n",
    "    \n",
    "    gene_set_n = list(map(N2I.get, gene_set))\n",
    "    names = '{}, {}'.format(*gene_set)\n",
    "    \n",
    "    cur_scores = []\n",
    "    cornell_set = []\n",
    "\n",
    "    \n",
    "    for gene in gene_set:\n",
    "        cornell_set.append(cornell_counts.index.get_loc(gene))\n",
    "    \n",
    "    for i in tqdm(range(10000), leave=False):\n",
    "        clf = SVC(gamma = 'auto', probability = True)\n",
    "        score = cross_validate(clf, scaled_cornell_counts[:, cornell_set], corn_SC2, scoring='roc_auc', cv=StratifiedKFold(n_splits=5, shuffle=True))\n",
    "        av = np.average(score['test_score'])\n",
    "        cur_scores.append(av)\n",
    "    \n",
    "    score1 = \"{:.3f} ({:.3f})\".format(np.average(cur_scores), np.std(cur_scores))\n",
    "    \n",
    "    \n",
    "    clf = SVC(gamma = 'auto')\n",
    "    clf.fit(TRcomb_counts[:, gene_set_n], TRcomb_SC2)\n",
    "    score2 = \"{:.3f}\".format(roc_auc_score(corn_SC2, clf.decision_function(scaled_cornell_counts[:,cornell_set])))\n",
    "    \n",
    "    display.append([names, score1, score2])\n",
    "    \n",
    "    \n",
    "pd.DataFrame(display, columns = ['Genes', '5-fold CV', 'Trained on 70%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loops over a number of gene sets to generate the following two scores:\n",
    "#\n",
    "#   CV score on the validation cohort\n",
    "#   Score on the validation cohort when trained on the training cohort\n",
    "\n",
    "all_pairs = [['HERC6', 'COA3'], \n",
    "             ['HERC6', 'TNIP3'], \n",
    "             ['HERC6', 'GBP5'], \n",
    "             ['IFI44L', 'FCGR1A'], \n",
    "             ['IFI44L', 'PTAFR'], \n",
    "             ['IFI44L', 'GBP5'], \n",
    "             ['IFI6', 'GBP5'], \n",
    "             ['IFI6', 'C15orf48'], \n",
    "             ['IFI6', 'GRINA']]\n",
    "\n",
    "display = []\n",
    "\n",
    "for gene_set in tqdm(all_pairs, leave=False):\n",
    "    \n",
    "    gene_set_n = list(map(N2I.get, gene_set))\n",
    "    names = '{}, {}'.format(*gene_set)\n",
    "    \n",
    "    cur_scores = []\n",
    "    cornell_set = []\n",
    "\n",
    "    \n",
    "    for gene in gene_set:\n",
    "        cornell_set.append(cornell_counts.index.get_loc(gene))\n",
    "    \n",
    "    #for i in tqdm(range(10000), leave=False):\n",
    "    #    clf = SVC(gamma = 'auto', probability = True)\n",
    "    #    score = cross_validate(clf, scaled_cornell_counts[:, cornell_set], corn_SC2, scoring='roc_auc', cv=StratifiedKFold(n_splits=5, shuffle=True))\n",
    "    #    av = np.average(score['test_score'])\n",
    "    #    cur_scores.append(av)\n",
    "    #\n",
    "    #score1 = \"{:.3f} ({:.3f})\".format(np.average(cur_scores), np.std(cur_scores))\n",
    "    \n",
    "    \n",
    "    clf = SVC(gamma = 'auto', probability = True)\n",
    "    clf.fit(TRcomb_counts[:, gene_set_n], TRcomb_SC2)\n",
    "    score2 = \"{:.3f}\".format(roc_auc_score(corn_SC2, clf.decision_function(scaled_cornell_counts[:,cornell_set])))\n",
    "    \n",
    "    #display.append([names, score1, score2])\n",
    "    display.append([names, score2])\n",
    "    \n",
    "    \n",
    "#pd.DataFrame(display, columns = ['Genes', '5-fold CV', 'Trained on 70%'])\n",
    "pd.DataFrame(display, columns = ['Genes', 'Trained on 70%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate single gene and 2-gene AUC scores for comparison with fold-change\n",
    "\n",
    "def all_gene_scores(add_set):\n",
    "    \n",
    "    all_scores = []\n",
    "    \n",
    "    \n",
    "    cornell_set = []\n",
    "    \n",
    "    for gene in add_set:\n",
    "        cornell_set.append(cornell_counts.index.get_loc(gene))\n",
    "    \n",
    "    \n",
    "    for i in range(scaled_cornell_counts.shape[1]):\n",
    "        cur_scores = []\n",
    "        if not i%100: print(i)\n",
    "        for j in range(5):\n",
    "            clf = SVC(gamma = 'auto', probability = True)\n",
    "            score = cross_validate(clf, scaled_cornell_counts[:, [i]+cornell_set], corn_SC2, scoring='roc_auc', cv=StratifiedKFold(n_splits=5, shuffle=True))\n",
    "            av = np.average(score['test_score'])\n",
    "            cur_scores.append(av)\n",
    "            \n",
    "        all_scores.append(cur_scores)\n",
    "    \n",
    "    avs = pd.DataFrame(cornell_counts.index.values, columns = ['Gene'])\n",
    "    avs['Score'] = np.average(all_scores, axis = 1)\n",
    "    \n",
    "    if add_set == []:\n",
    "        np.savetxt(\"new_york_one_gene_scores.csv\", avs.sort_values('Score', ascending = False), delimiter=\",\", fmt='%s')\n",
    "    else:\n",
    "        np.savetxt(\"new_york_scores_with_\"+\"_\".join(add_set)+\".csv\", avs.sort_values('Score', ascending = False), delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_gene_scores([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_gene_scores(['IFI6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gene_scores(['IFI44L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_gene_scores(['HERC6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
